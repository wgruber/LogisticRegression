<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Evaluierung des Modells | Logistische Regression</title>
  <meta name="description" content="Methodenlehre und Statistik 3" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Evaluierung des Modells | Logistische Regression" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/Images/Cover.png" />
  <meta property="og:description" content="Methodenlehre und Statistik 3" />
  <meta name="github-repo" content="wgruber/LogisticRegression" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Evaluierung des Modells | Logistische Regression" />
  
  <meta name="twitter:description" content="Methodenlehre und Statistik 3" />
  <meta name="twitter:image" content="/Images/Cover.png" />

<meta name="author" content="W. R. Gruber" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="theorie-der-logistischen-regression.html"/>
<link rel="next" href="anwendungsbeispiel.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Logistische Regression</a></li>

<li class="divider"></li>
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="chapter" data-level="" data-path="vorbemerkung.html"><a href="vorbemerkung.html"><i class="fa fa-check"></i>Vorbemerkung</a></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a>
<ul>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html#beispiele-aus-der-psychologie"><i class="fa fa-check"></i>Beispiele aus der Psychologie</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="grundlegende-idee.html"><a href="grundlegende-idee.html"><i class="fa fa-check"></i>Grundlegende Idee</a>
<ul>
<li class="chapter" data-level="" data-path="grundlegende-idee.html"><a href="grundlegende-idee.html#einführendes-beispiel"><i class="fa fa-check"></i>Einführendes Beispiel</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html"><i class="fa fa-check"></i>Theorie der logistischen Regression</a>
<ul>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#lineare-modelle"><i class="fa fa-check"></i>Lineare Modelle</a></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#logistische-funktion"><i class="fa fa-check"></i>Logistische Funktion</a></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#odds-ratio"><i class="fa fa-check"></i>Odds Ratio</a></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#interpretation-der-odds-ratio-im-kontext-therapieerfolg"><i class="fa fa-check"></i>Interpretation der Odds-Ratio im Kontext Therapieerfolg</a>
<ul>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#a-fall-1-eb-1-kein-einfluss"><i class="fa fa-check"></i>a) Fall 1: <span class="math inline">\(e^{b} = 1\)</span> — Kein Einfluss</a></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#b-fall-2-eb-1-erhöhte-erfolgswahrscheinlichkeit"><i class="fa fa-check"></i>b) Fall 2: <span class="math inline">\(e^{b} &gt; 1\)</span> — Erhöhte Erfolgswahrscheinlichkeit</a></li>
<li class="chapter" data-level="" data-path="theorie-der-logistischen-regression.html"><a href="theorie-der-logistischen-regression.html#c-fall-3-eb-1-verringerte-erfolgswahrscheinlichkeit"><i class="fa fa-check"></i>c) Fall 3: <span class="math inline">\(e^{b} &lt; 1\)</span> — Verringerte Erfolgswahrscheinlichkeit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html"><i class="fa fa-check"></i>Evaluierung des Modells</a>
<ul>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#likelihood-und-log-likelihood"><i class="fa fa-check"></i>Likelihood und Log-Likelihood</a>
<ul>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#definition-der-likelihood"><i class="fa fa-check"></i>Definition der Likelihood</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#die-log-likelihood"><i class="fa fa-check"></i>Die Log-Likelihood</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#anwendung-in-der-parameterschätzung"><i class="fa fa-check"></i>Anwendung in der Parameterschätzung</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#anwendung-in-der-logistischen-regression"><i class="fa fa-check"></i>Anwendung in der Logistischen Regression</a>
<ul>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#die-deviance-statistic-delta-d"><i class="fa fa-check"></i>Die Deviance-Statistic (<span class="math inline">\(\Delta D\)</span>)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#anschauliche-erklärung"><i class="fa fa-check"></i>Anschauliche Erklärung</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#wald-statistik"><i class="fa fa-check"></i>Wald Statistik</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#pseudobestimmtheitsmaß-pseudo-r2-oder-mcfaddens-r2"><i class="fa fa-check"></i>Pseudobestimmtheitsmaß (Pseudo-<span class="math inline">\(R^2\)</span> oder McFadden’s <span class="math inline">\(R^2\)</span>)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#genauigkeit-accuracy"><i class="fa fa-check"></i>Genauigkeit (Accuracy)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#präzision-precision"><i class="fa fa-check"></i>Präzision (Precision)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#recall-sensitivität-oder-true-positive-rate"><i class="fa fa-check"></i>Recall (Sensitivität oder True Positive Rate)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#f1-score"><i class="fa fa-check"></i>F1-Score</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#receiver-operating-characteristic-roc-curve"><i class="fa fa-check"></i>Receiver Operating Characteristic (ROC) Curve</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#area-under-the-roc-curve-auc-roc"><i class="fa fa-check"></i>Area Under the ROC Curve (AUC-ROC)</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#konfusionsmatrix-confusion-matrix"><i class="fa fa-check"></i>Konfusionsmatrix (Confusion Matrix):</a></li>
<li class="chapter" data-level="" data-path="evaluierung-des-modells.html"><a href="evaluierung-des-modells.html#zusammenfassung"><i class="fa fa-check"></i>Zusammenfassung</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html"><i class="fa fa-check"></i>Anwendungsbeispiel</a>
<ul>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#datenvorverarbeitung"><i class="fa fa-check"></i>Datenvorverarbeitung</a>
<ul>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#schlafprobleme-und-alkohol"><i class="fa fa-check"></i>Schlafprobleme und Alkohol</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#schlafprobleme-und-einkommen"><i class="fa fa-check"></i>Schlafprobleme und Einkommen</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#schlafprobleme-und-kaffe"><i class="fa fa-check"></i>Schlafprobleme und Kaffe</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#modellanpassung"><i class="fa fa-check"></i>Modellanpassung</a>
<ul>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#zusammenhang-der-prädiktoren"><i class="fa fa-check"></i>Zusammenhang der Prädiktoren</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#vorhersagen"><i class="fa fa-check"></i>Vorhersagen</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#vorhersagen-mit-unserem-logistischen-modell"><i class="fa fa-check"></i>Vorhersagen mit unserem logistischen Modell</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#von-wahrscheinlichkeiten-zu-klassifikationen"><i class="fa fa-check"></i>Von Wahrscheinlichkeiten zu Klassifikationen</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#modellevaluierung"><i class="fa fa-check"></i>Modellevaluierung</a>
<ul>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#genauigkeit-accuracy-1"><i class="fa fa-check"></i>Genauigkeit (Accuracy)</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#sensitivität-spezifität-und-die-konfusionsmatrix"><i class="fa fa-check"></i>Sensitivität, Spezifität und die Konfusionsmatrix</a></li>
<li class="chapter" data-level="" data-path="anwendungsbeispiel.html"><a href="anwendungsbeispiel.html#roc-auc"><i class="fa fa-check"></i>ROC &amp; AUC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://wgruber.github.io/LogisticRegression" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Logistische Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="evaluierung-des-modells" class="section level1 hasAnchor">
<h1>Evaluierung des Modells<a href="evaluierung-des-modells.html#evaluierung-des-modells" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Bei der Evaluierung eines logistischen Regressionsmodells gibt es mehrere Kennwerte und Metriken, die üblicherweise verwendet werden, um die Qualität und Aussagekraft des Modells zu bewerten. Nachfolgend sind einige der wichtigsten Methoden beschrieben.</p>
<div id="likelihood-und-log-likelihood" class="section level2 hasAnchor">
<h2>Likelihood und Log-Likelihood<a href="evaluierung-des-modells.html#likelihood-und-log-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Um eine Bewertung für die Eignung des linearen Modells zu erhalten, haben wir den Determinationskoeffizienten / das Bestimmtheitsmaß (<span class="math inline">\(R^2\)</span>, den quadrierten Pearson Korrelationkoeffizienten) verwendet.</p>
<p>Bei der logistischen Regression verwenden wir nun die Log-Likelihood. Allgemein ist die Likelihood ein zentrales Konzept in der Statistik, vor allem bei der Parameterschätzung. Die Parameter<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> eines Modells werden häufig mit dem griechischen Buchstaben <span class="math inline">\(\theta\)</span> bezeichnet. Die Likelihood ist eine Funktion von <span class="math inline">\(\theta\)</span>, die angibt, wie <em>plausibel</em> die beobachteten Daten für verschiedene Parameterwerte sind.</p>
<p><span class="math inline">\(\theta\)</span> wäre in unserem Therapeuten-Beispiel typischerweise der Vektor der Regressionskoeffizienten (z.B. <span class="math inline">\((b_0, b_1)\)</span>, die den Zusammenhang zwischen Erfolgsrate und Therapieerfolg beschreiben.</p>
<p>Allgemeine Beispiele für <span class="math inline">\(\theta\)</span> sind:</p>
<ul>
<li>Bei einer <strong>Normalverteilung</strong>:
<ul>
<li><span class="math inline">\(\theta = \mu\)</span> (Erwartungswert)</li>
<li><span class="math inline">\(\theta = \sigma^2\)</span> (Varianz)</li>
<li>oder als Vektor: <span class="math inline">\(\theta = (\mu, \sigma^2)\)</span></li>
</ul></li>
<li>Bei einer <strong>Binomialverteilung</strong>: <span class="math inline">\(\theta = p\)</span> (Wahrscheinlichkeit für Erfolg bei einem Versuch)</li>
<li>Bei einer <strong>Poissonverteilung</strong>: <span class="math inline">\(\theta = \lambda\)</span> (Erwartungswert/Rate)</li>
<li>Bei einer <strong>Logistischen Regression</strong>: <span class="math inline">\(\theta = \text{ Regressionskoeffizienten } (b_0, b_1, \cdots)\)</span></li>
</ul>
<div id="definition-der-likelihood" class="section level3 hasAnchor">
<h3>Definition der Likelihood<a href="evaluierung-des-modells.html#definition-der-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Angenommen, wir haben Beobachtungen <span class="math inline">\(x_1, x_2, \dots, x_n\)</span>, die als unabhängige Realisierungen einer Zufallsvariablen<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> angesehen werden. Wenn das Modell von einem Parameter <span class="math inline">\(\theta\)</span> abhängt, dann ist die Likelihood-Funktion definiert als:</p>
<p><span class="math display">\[L(\theta) = P(x_1, x_2, \dots, x_n \mid \theta).\]</span></p>
<p><strong>Wichtig zu beachten:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Diskrete vs. stetige Daten</strong>
<ul>
<li>Bei <strong>diskreten</strong> Zufallsvariablen ist <span class="math inline">\(P(x_1, \dots, x_n\mid\theta)\)</span> eine <strong>Wahrscheinlichkeitsfunktion</strong>.<br />
</li>
<li>Bei <strong>stetigen</strong> Zufallsvariablen schreibt man für die <em>Dichtefunktion</em> <span class="math inline">\(f(\cdot\mid\theta)\)</span> korrekterweise:</li>
</ul></li>
</ol>
<p><span class="math display">\[L(\theta) \;=\; f(x_1, x_2, \dots, x_n \mid \theta)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Funktion in <span class="math inline">\(\theta\)</span></strong>
<ul>
<li>Formal ist <span class="math inline">\(L(\theta)\)</span> <em>keine</em> Wahrscheinlichkeitsverteilung über <span class="math inline">\(\theta\)</span>, sondern eine Funktion, die angibt, wie <em>plausibel</em> die beobachteten Daten für verschiedene <span class="math inline">\(\theta\)</span>-Werte sind.</li>
</ul></li>
<li><strong>Unabhängigkeit der Beobachtungen</strong><br />
Haben <span class="math inline">\((x_1,\dots,x_n)\)</span> die gemeinsame Verteilung <span class="math inline">\(P(\cdot\mid\theta)\)</span> und sind sie <strong>unabhängig</strong>, so zerfällt die Likelihood in ein Produkt der Einzelwahrscheinlichkeiten bzw. -dichten:</li>
</ol>
<p><span class="math display">\[L(\theta) = P(x_1, \dots, x_n \mid \theta)  = \prod_{i=1}^n P(x_i \mid \theta) \quad\text{bzw.}\quad    \prod_{i=1}^n f(x_i \mid \theta)\]</span></p>
<p>Die Likelihood ist das Produkt mehrerer Wahrscheinlichkeitsdichten (Werte <span class="math inline">\(\leq 1\)</span>), daher wird das Ergebnis meist schnell <strong>sehr klein</strong> - besonders, wenn viele Beobachtungen vorkommen. Einzelne Dichtewerte (wie z.B. bei der Normalverteilung) sind normalerweise schon kleiner als 1, und das Produkt von mehreren dieser Werte ergibt dann eine noch kleinere Zahl. Daher ist bei der Interpretation der Likelihood folgendes zu beachten:</p>
<ul>
<li>Die <strong>absolute Höhe</strong> der Likelihood ist <strong>nicht</strong> direkt interpretierbar, da sie von der Anzahl der Daten und der Skalierung abhängt.</li>
<li><strong>Wichtig ist der Vergleich:</strong> man kann Likelihood-Werte für verschiedene Parameter <span class="math inline">\(b_0, b_1, \lambda, \mu\)</span> vergleichen. Der Parameter, für den die Likelihood <strong>am größten ist</strong>, passt am besten zu den Daten ( = <strong>Maximum-Likelihood-Schätzer</strong>, siehe weiter unten).</li>
<li>Die Likelihood selbst ist <strong>keine Wahrscheinlichkeit</strong>, sondern eben ein (oft kleiner) Wert, der beschreibt, wie plausibel die Parameterwerte angesichts der Daten sind. Sie ist nur zum <strong>Vergleich von Parametern</strong> gedacht, um zu entscheiden, welcher Wert des Parameters die beobachteten Daten am besten erklären würde.</li>
</ul>
</div>
<div id="die-log-likelihood" class="section level3 hasAnchor">
<h3>Die Log-Likelihood<a href="evaluierung-des-modells.html#die-log-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Das direkte Arbeiten mit dem Produkt in der Likelihood kann aufgrund von numerischen Problemen, wie sehr kleinen Zahlen, unhandlich sein. Daher wendet man den Logarithmus an, was zur <strong>Log-Likelihood (LL)</strong> führt. Die Log-Likelihood ist definiert als:</p>
<p><span class="math display">\[LL(\theta) = \log_e \left( L(\theta) \right) = \log_e \left( \prod_{i=1}^{n} P(x_i \mid \theta) \right).\]</span>
Durch Anwendung der Logarithmengesetze wird das Produkt in eine Summe umgewandelt:</p>
<p><span class="math display">\[LL(\theta) = \sum_{i=1}^{n} \log_e \left( P(x_i \mid \theta) \right).\]</span>
Diese Transformation hat mehrere Vorteile:</p>
<ul>
<li><p><strong>Mathematische Vereinfachung:</strong> Summen lassen sich in Ableitungen und Optimierungsverfahren einfacher handhaben als Produkte.</p></li>
<li><p><strong>Numerische Stabilität:</strong> Der Logarithmus verhindert, dass extrem kleine Produktwerte, die bei vielen Beobachtungen auftreten können, zu Rundungsfehlern führen.</p></li>
</ul>
</div>
<div id="anwendung-in-der-parameterschätzung" class="section level3 hasAnchor">
<h3>Anwendung in der Parameterschätzung<a href="evaluierung-des-modells.html#anwendung-in-der-parameterschätzung" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In der Maximum-Likelihood-Methode wird der Parameterwert <span class="math inline">\(\theta\)</span> gesucht, der die Log-Likelihood maximiert. Dieser Schätzer, der sogenannte Maximum-Likelihood-Schätzer (MLE), liefert die Parameter, unter denen das Modell die beobachteten Daten am wahrscheinlichsten macht.</p>
</div>
</div>
<div id="anwendung-in-der-logistischen-regression" class="section level2 hasAnchor">
<h2>Anwendung in der Logistischen Regression<a href="evaluierung-des-modells.html#anwendung-in-der-logistischen-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Die logistische Regression modelliert auf der Grundlage von Beobachtungen <span class="math inline">\((Y)\)</span> die Wahrscheinlichkeit, ob ein Ereignis <span class="math inline">\(P(Y)\)</span> eintritt, oder nicht. Für eine bestimmte Person <span class="math inline">\(i\)</span> ist das beobachtete Ergebnis <span class="math inline">\(Y_i\)</span> entweder 0 oder 1, aber der vorhergesagte Wert <span class="math inline">\(P(\hat{Y}_i)\)</span> ist ein Wert zwischen 0 und 1.</p>
<p>Bei der Bewertung der Anpassung des <em>linearen Modells</em> haben wir die beobachteten und vorhergesagten Werte des Ergebnisses verglichen und <span class="math inline">\(R^2\)</span> (das Bestimmtheitsmaß) zur Bewertung der Modellanpassung verwendet.Bei der <strong>logistischen Regression</strong> wird die <strong>Log-Likelihood (LL)</strong> verwendet. Betrachten wir dazu:</p>
<p><span class="math display">\[LL = \sum_{i=1}^{n}(Y_i \cdot ln(P(\hat{Y}_i)) + (1 - Y_i) \cdot ln(P(1 - \hat{Y}_i))\]</span></p>
<p>Diese Summe der Wahrscheinlichkeiten gibt Auskunft über die nicht erklärte Information, die nach Anwedung des Modells verbleibt. Da es sich um Wahrscheinlichkeiten im Wertebereich <span class="math inline">\(LL \in [0, 1]\)</span> handelt, ist der Logarithmus von LL stets eine negative Zahl. Daraus folgt, dass große Werte der Log-Likelihood-Statistik auf schlecht passende statistische Modelle hinweisen, denn je größer der Wert der Log-Likelihood, desto mehr unerklärte Varianzbeobachtungen gibt es.</p>
<div id="die-deviance-statistic-delta-d" class="section level3 hasAnchor">
<h3>Die Deviance-Statistic (<span class="math inline">\(\Delta D\)</span>)<a href="evaluierung-des-modells.html#die-deviance-statistic-delta-d" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ein Nachteil der <span class="math inline">\(LL\)</span>-Modellschätzung ist der negative Wert und eine fehlende Vergleichsverteilung für die Schätzung der Signifikanz eines Modellunterschiedes. Durch Multiplikation der LL mit dem Faktor -2 erhalten wir die sogenannte Deviance (<span class="math inline">\(\delta D\)</span>):</p>
<p><span class="math display">\[\Delta D= -2 \cdot LL\]</span></p>
<p>wobei <span class="math inline">\(LL\)</span> die Likelihood des Modells ist. Das Minus-Zeichen und der Faktor 2 haben unter anderem folgende Gründe:</p>
<ul>
<li><strong>Vergleichbarkeit:</strong> durch die Multiplikation mit -2 wird die Deviance positiv und so skaliert, dass sie asymptotisch (bei großen Stichproben) einer <span class="math inline">\(\chi^2\)</span>-Verteilung folgt, was Vergleiche und Signifikanztests, wie z. B. den Likelihood-Ratio-Test<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, ermöglicht. Die <span class="math inline">\(\chi^2\)</span>-Statistisk berechnet sich aus (<strong>Bemerkung:</strong> die Freiheitsgrade <span class="math inline">\(k\)</span> entsprechen der Anzahl der im Modell verwendeten Parameter. Im <em>Null-Modell</em> (<span class="math inline">\(Model_0\)</span>) ist <span class="math inline">\(k = 1\)</span>, in erweiterten Modellen jeweils der Anzahl der Prädiktoren + 1 (für den konstanten Term)):</li>
</ul>
<p><span class="math display">\[\chi^2 = (-2 \cdot LL_{Model_0}) - (-2 \cdot LL_{Model_1})\]</span>
<span class="math display">\[\chi^2 = 2 \cdot LL_{Model_1} - 2 \cdot LL_{Model_0}\]</span>
<span class="math display">\[df = k_1 - k_0\]</span></p>
<ul>
<li><strong>Interpretation:</strong> Ein kleinerer Deviance-Wert zeigt an, dass das Modell eine höhere Likelihood (bzw. eine bessere Anpassung an die Daten) aufweist. Ist die Deviance besonders klein, passen die vom Modell vorhergesagten Wahrscheinlichkeiten gut zu den beobachteten Ausprägungen.</li>
</ul>
</div>
<div id="anschauliche-erklärung" class="section level3 hasAnchor">
<h3>Anschauliche Erklärung<a href="evaluierung-des-modells.html#anschauliche-erklärung" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Stellen wir uns vor, dass wir zwei Modelle betrachten möchten:</p>
<ul>
<li>Ein <strong>Modell 0</strong>, das nur einen konstanten Wert (bei der logistischen Regression ist dies die am häufigsten auftretende Ergebniskategorie, was einer Vorhersage des Ergebnisses anhand des Achsenabschnitts entspricht).</li>
<li>Ein <strong>Modell 1</strong>, das zusätzlich weitere Prädiktoren enthält und komplexere Zusammenhänge abbilden kann.</li>
</ul>
<p>Das Modell mit der höheren Likelihood (also besserer Anpassung an die Daten) wird auch einen niedrigeren <span class="math inline">\(-2 \cdot LL\)</span>-Wert aufweisen – sprich, <strong>eine niedrigere Deviance</strong>. Wenn der Vergleich zeigt, dass die Erweiterung von Modell 0 zu Modell 1 zu einer signifikanten Reduktion der Deviance führt, spricht dies für einen Mehrwert der zusätzlichen Prädiktoren.</p>
</div>
</div>
<div id="wald-statistik" class="section level2 hasAnchor">
<h2>Wald Statistik<a href="evaluierung-des-modells.html#wald-statistik" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Wie bereits bei der (multiplen) linearen Regression, sind auch bei der logistische Regression an einer statistischen Absicherung der Parameter interessiert. Mit der Wald-Statistik kann die Bedeutung einzelner Prädiktoren in einem logistischen Regressionsmodell getestet werden.</p>
<p>Für dieses Modell gibt es analog zur <span class="math inline">\(t\)</span>-Statistik (<span class="math inline">\(b / SE_{b}\)</span>) eine <span class="math inline">\(z\)</span>-Statistik. Wenn der Koeffizient signifikant von Null abweicht, kann man davon ausgehen, dass der Prädiktor einen signifikanten Beitrag zur Vorhersage des Ergebnisses leistet. Die folgende Gleichung zeigt, wie die z-Statistik berechnet wird:</p>
<p><span class="math display">\[z=\frac{b}{SE_b}\]</span></p>
<p>Damit ist diese Statistik im Grunde identisch mit der t-Statistik im linearen Modell!</p>
<p>Wie <span class="citation">(<a href="#ref-Menart">Menart 2002</a>)</span> zeigen konnte, wird der Standardfehler für große <span class="math inline">\(b\)</span>-Werte ungenau (größer), was zu einer Unterschätzung der <span class="math inline">\(z\)</span>-Statistik führt. Dies erhöht die Wahrscheinlichkeit, dass ein Prädiktor als nicht signifikant ausgewiesen wird, obwohl er in Wirklichkeit einen signifikanten Beitrag zum Modell leistet. Eine Alternative wäre die Prädiktoren hierarchisch einzugeben und die Veränderung in der Likelihood-Ratio-Statistik zu untersuchen.</p>
</div>
<div id="pseudobestimmtheitsmaß-pseudo-r2-oder-mcfaddens-r2" class="section level2 hasAnchor">
<h2>Pseudobestimmtheitsmaß (Pseudo-<span class="math inline">\(R^2\)</span> oder McFadden’s <span class="math inline">\(R^2\)</span>)<a href="evaluierung-des-modells.html#pseudobestimmtheitsmaß-pseudo-r2-oder-mcfaddens-r2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In der linearen Regression beschreibt <span class="math inline">\(R^2\)</span> den Anteil der Varianz, der durch das Modell erklärt wird. In der logistischen Regression ist das standardmäßige <span class="math inline">\(R^2\)</span> jedoch nicht anwendbar. Stattdessen gibt es Pseudo-<span class="math inline">\(R^2\)</span>-Maße wie McFadden’s R², die den relativen Informationsgewinn eines Modells im Vergleich zu einem Nullmodell angeben.</p>
<p>Das Maß hilft quantifiziert, wie gut das Modell Daten im Vergleich zu einem Modell ohne Prädiktoren erklärt.</p>
</div>
<div id="genauigkeit-accuracy" class="section level2 hasAnchor">
<h2>Genauigkeit (Accuracy)<a href="evaluierung-des-modells.html#genauigkeit-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Der Anteil der korrekt vorhergesagten Beobachtungen im Vergleich zur Gesamtanzahl der Beobachtungen.</p>
<p>Der Vorteil an diesem Maß ist, dass es einfach zu berechnen und zu verstehen. Allerdings kann es auch irreführend sein, wenn die Verteilung der Fälle in den Klassen unausgeglichen sind, da sie die Dominanz der Mehrheitspopulation betont.</p>
</div>
<div id="präzision-precision" class="section level2 hasAnchor">
<h2>Präzision (Precision)<a href="evaluierung-des-modells.html#präzision-precision" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Beschreibung: Der Anteil der richtig vorhergesagten positiven Beobachtungen im Vergleich zur Gesamtzahl der vorhergesagten positiven Beobachtungen.</p>
<p>Diese Maß ist vor allem nützlich, wenn die <em>Kosten</em> für falsch-positive Ergebnisse hoch sind. Es ist zu beachten, dass die falsch-negativen Ergebnisse nicht berücksichtigt werden!</p>
</div>
<div id="recall-sensitivität-oder-true-positive-rate" class="section level2 hasAnchor">
<h2>Recall (Sensitivität oder True Positive Rate)<a href="evaluierung-des-modells.html#recall-sensitivität-oder-true-positive-rate" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Der Anteil der richtig vorhergesagten positiven Beobachtungen im Vergleich zur Gesamtzahl der tatsächlichen positiven Beobachtungen. Das ist vor allem dann wichtig, wenn das Auffinden aller positiven Instanzen entscheidend ist. Allerdings berücksichtigt dieses Maß nicht die falsch-positiven Ergebnisse nicht.</p>
</div>
<div id="f1-score" class="section level2 hasAnchor">
<h2>F1-Score<a href="evaluierung-des-modells.html#f1-score" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Der harmonische Mittelwert von Präzision und Recall. Dadurch gibt eine ausgeglichene Sichtweise, wenn sowohl Präzision als auch Recall wichtig sind.</p>
</div>
<div id="receiver-operating-characteristic-roc-curve" class="section level2 hasAnchor">
<h2>Receiver Operating Characteristic (ROC) Curve<a href="evaluierung-des-modells.html#receiver-operating-characteristic-roc-curve" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Eine grafische Darstellung der True Positive Rate gegen die False Positive Rate bei verschiedenen Schwellenwerten. Bietet eine umfassende Visualisierung der Klassifikationsleistung für alle möglichen Schwellenwerte, kann aber ann bei unausgeglichenen Klassen in die Irre führen, da sie alle Schwellenwerte gleich gewichtet.</p>
</div>
<div id="area-under-the-roc-curve-auc-roc" class="section level2 hasAnchor">
<h2>Area Under the ROC Curve (AUC-ROC)<a href="evaluierung-des-modells.html#area-under-the-roc-curve-auc-roc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ein skalarloser Wert, der die Fähigkeit des Modells misst, positive von negativen Klassen zu trennen. Misst die Gesamtleistung des Modells und ist gut geeignet für unausgeglichene Klassenverteilungen.</p>
</div>
<div id="konfusionsmatrix-confusion-matrix" class="section level2 hasAnchor">
<h2>Konfusionsmatrix (Confusion Matrix):<a href="evaluierung-des-modells.html#konfusionsmatrix-confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Eine Tabelle, die die Häufigkeiten von True Positives, False Positives, True Negatives und False Negatives zusammenfasst. Bietet detaillierte Einblicke in die Vorhersageleistungen, kann aber bei großen Datensätzen schwer zu interpretieren sein.</p>
<center>
<div class="float">
<img src="Images/Konfussionsmatrix.jpg" style="width:70.0%" alt="Abbildung 2: Wahrheistmatrix (Konfusionsmatrix)" />
<div class="figcaption"><strong>Abbildung 2</strong>: Wahrheistmatrix (Konfusionsmatrix)</div>
</div>
</center>
</div>
<div id="zusammenfassung" class="section level2 hasAnchor">
<h2>Zusammenfassung<a href="evaluierung-des-modells.html#zusammenfassung" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Jede dieser Metriken bietet spezifische Einblicke in die Leistungsfähigkeit eines logistischen Regressionsmodells. Die Wahl der Metrik sollte von den spezifischen Anforderungen und Prioritäten der Anwendung abhängen, einschließlich der Bedeutung von falsch-positiven und falsch-negativen Ergebnissen.</p>
<p>Zusammenfassend ergänzen sich diese Ansätze, indem sie unterschiedliche Aspekte der logistischen Regression beleuchten. Für eine umfassende Modellbewertung in der Praxis ist es sinnvoll, beide Gruppen von Metriken zu berücksichtigen: Die ersteren zur Beurteilung der Klassifikationsleistung und die letzteren für Einblicke in die Modellanpassung und die Rolle einzelner Prädiktoren.</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Menart" class="csl-entry">
Menart, S. 2002. <span>“Applied Logistic Regression Analysis.”</span> <em>Sage Publications</em>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Parameter sind die bestimmenden Elemente einer Funktion, bzw. eines Elementes. Bei der linearen Regression ist es der Interzept <span class="math inline">\(b_0\)</span> und die Steigung <span class="math inline">\(b_1\)</span>, die eindeutig eine Gerade in der Ebene bestimmen. Damit sind <span class="math inline">\(b_0\)</span> und <span class="math inline">\(b_1\)</span> die Parameter der linearen Funktion.<a href="evaluierung-des-modells.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>In der Stochastik ist eine Zufallsvariable eine Größe, deren Wert vom Zufall abhängig ist. Formal ist eine Zufallsvariable eine Funktion, die jedem möglichen Ergebnis eines Zufallsexperiments eine Größe zuordnet. Beispiele für reelle Zufallsvariablen sind die Augensumme von zwei geworfenen Würfeln und die Gewinnhöhe in einem Glücksspiel (Definition Wikipedia).<a href="evaluierung-des-modells.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>es gilt für <span class="math inline">\(log \left( \frac{A}{B} \right) = log(A) - log(B)\)</span>. Damit sollte klar sein, warum man von Ratio-Test sprechen kann, obwohl die Differenz zweier log-Werte in der Formel dargestellt wird!<a href="evaluierung-des-modells.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="theorie-der-logistischen-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="anwendungsbeispiel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
